- Final exam review session: 2 hours, totally optional, group study
- project is a thing
Final stuff:
- shouldn't need a calculator: If you think you do, something's wrong
$\gamma_{ic}$ responsibilities: prob. of point i generated by component c (soft)
- gaussian mixture model
- everything is kinda everything's datapoint
## Baysean Decision Theory
- how to make optimal decisions when we have "perfect information"
- Assume $x \in R^D$, true $p(y|x)$ known. Goal: pick the "best" $y$
Scenario: A joint baby shower
- $x \in R$: a measurement of how pregnant someone looks (intentionally uncomfortable)
- Using ML to determine who to say "congratulations" to
	- non-deterministic
- assymetry of consequences: false negatives vs false positives
- How do we set the decision bodary policy?
	- picking $h$ to minimize risk ($E[L(h(x), y)]$)
	- minimize $\sum_{m=1}^CL(m, h(x))p(Y=m|x)$ over all $x$
Bayes Decision Rule:
$$h(x)=\arg\min_i\sum_{m=1}^CL(m,i)p(Y=m|x)$$
Bayes risk: (usually $\neq 0$)
$$R^*=\min_hR(h)$$
If we congratulate:
$$L(R=y,h(x)=y)p(R=Y|x) + L(R=n,h(x)=y)p(R=n|x) < L(R=y,h(x)=n)p(R=y|x) + \dots$$
Suppose that the false positive risk is 10x the false negative risk
$$10p(R=n|x)<p(R=y|x)$$

### Zero-one loss function
$L(y,h(x)) = \delta(y\neq h(x))$ 0 if $y = h(x)$, 1 else

Decision rule:
$$\arg\max_i p(Y=i|x)$$

$R^*$ is Bayes Error