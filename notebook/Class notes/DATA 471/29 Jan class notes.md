TODO: representational neural networks; last flipped module

## Non-linear predictions
Using a linear model on some non-linear transformation of some data
- fixed $\phi(x)$, e.g. polynomial feature expansion
- implicit fixed $\phi(x)$ - SVMs
	- implicit: never actually producing $\phi(x)$ vector
- learned $\phi(x)$ transform
Exerting control, intuition

expanding expressiveness/power; need to have enough data to learn it

feature engineering; knowing what's important

## Layers
Linear transformation, activation

- Linear models = 1 layer
- simplest neural net: 2 layers; hidden layer

